{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import edhec_risk_kit_206 as erk\n",
    "\n",
    "ind49_rets = erk.get_ind_returns(weighting=\"vw\", n_inds=49)[\"2013\":]\n",
    "ind49_mcap = erk.get_ind_market_caps(49, weights=True)[\"2013\":]\n",
    "inds = ['Hlth', 'Fin', 'Whlsl', 'Rtail', 'Food']\n",
    "rho_ = ind49_rets[inds].corr()\n",
    "vols_ = (ind49_rets[inds].std()*np.sqrt(12))    \n",
    "sigma_prior_ =  (vols_.T).dot(vols_) * rho_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def as_colvec(x):\n",
    "    if (x.ndim == 2):\n",
    "        return x\n",
    "    else:\n",
    "        return np.expand_dims(x, axis=1)\n",
    "\n",
    "def implied_returns(delta, sigma, w):\n",
    "    \"\"\"\n",
    "Obtain the implied expected returns by reverse engineering the weights\n",
    "Inputs:\n",
    "delta: Risk Aversion Coefficient (scalar)\n",
    "sigma: Variance-Covariance Matrix (N x N) as DataFrame\n",
    "    w: Portfolio weights (N x 1) as Series\n",
    "Returns an N x 1 vector of Returns as Series\n",
    "    \"\"\"\n",
    "    ir = delta * sigma.dot(w).squeeze() # to get a series from a 1-column dataframe\n",
    "    ir.name = 'Implied Returns'\n",
    "    return ir\n",
    "\n",
    "# Assumes that Omega is proportional to the variance of the prior\n",
    "def proportional_prior(sigma, tau, p):\n",
    "    \"\"\"\n",
    "    Returns the He-Litterman simplified Omega\n",
    "    Inputs:\n",
    "    sigma: N x N Covariance Matrix as DataFrame\n",
    "    tau: a scalar\n",
    "    p: a K x N DataFrame linking Q and Assets\n",
    "    returns a P x P DataFrame, a Matrix representing Prior Uncertainties\n",
    "    \"\"\"\n",
    "    helit_omega = p.dot(tau * sigma).dot(p.T)\n",
    "    # Make a diag matrix from the diag elements of Omega\n",
    "    return pd.DataFrame(np.diag(np.diag(helit_omega.values)),index=p.index, columns=p.index)\n",
    "from numpy.linalg import inv\n",
    "\n",
    "def bl(w_prior, sigma_prior, p, q,\n",
    "                omega=None,\n",
    "                delta=2.5, tau=.02):\n",
    "    \"\"\"\n",
    "# Computes the posterior expected returns based on \n",
    "# the original black litterman reference model\n",
    "#\n",
    "# W.prior must be an N x 1 vector of weights, a Series\n",
    "# Sigma.prior is an N x N covariance matrix, a DataFrame\n",
    "# P must be a K x N matrix linking Q and the Assets, a DataFrame\n",
    "# Q must be an K x 1 vector of views, a Series\n",
    "# Omega must be a K x K matrix a DataFrame, or None\n",
    "# if Omega is None, we assume it is\n",
    "#    proportional to variance of the prior\n",
    "# delta and tau are scalars\n",
    "    \"\"\"\n",
    "    if omega is None:\n",
    "        omega = proportional_prior(sigma_prior, tau, p)\n",
    "    # Force w.prior and Q to be column vectors\n",
    "    # How many assets do we have?\n",
    "    N = w_prior.shape[0]\n",
    "    # And how many views?\n",
    "    K = q.shape[0]\n",
    "    # First, reverse-engineer the weights to get pi\n",
    "    pi = implied_returns(delta, sigma_prior,  w_prior)\n",
    "    # Adjust (scale) Sigma by the uncertainty scaling factor\n",
    "    sigma_prior_scaled = tau * sigma_prior  \n",
    "    # posterior estimate of the mean, use the \"Master Formula\"\n",
    "    # we use the versions that do not require\n",
    "    # Omega to be inverted (see previous section)\n",
    "    # this is easier to read if we use '@' for matrixmult instead of .dot()\n",
    "    #     mu_bl = pi + sigma_prior_scaled @ p.T @ inv(p @ sigma_prior_scaled @ p.T + omega) @ (q - p @ pi)\n",
    "    mu_bl = pi + sigma_prior_scaled.dot(p.T).dot(inv(p.dot(sigma_prior_scaled).dot(p.T) + omega).dot(q - p.dot(pi).values))\n",
    "    # posterior estimate of uncertainty of mu.bl\n",
    "#     sigma_bl = sigma_prior + sigma_prior_scaled - sigma_prior_scaled @ p.T @ inv(p @ sigma_prior_scaled @ p.T + omega) @ p @ sigma_prior_scaled\n",
    "    sigma_bl = sigma_prior + sigma_prior_scaled - sigma_prior_scaled.dot(p.T).dot(inv(p.dot(sigma_prior_scaled).dot(p.T) + omega)).dot(p).dot(sigma_prior_scaled)\n",
    "    return (mu_bl, sigma_bl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_eq = ind49_mcap[inds].iloc[0]\n",
    "w_eq = w_eq/w_eq.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hlth     0.041663\n",
       "Whlsl    0.097411\n",
       "Food     0.139176\n",
       "Fin      0.175362\n",
       "Rtail    0.546388\n",
       "Name: 2013-01, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_eq.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hlth     0.152910\n",
       "Food     0.158115\n",
       "Fin      0.175580\n",
       "Whlsl    0.201836\n",
       "Rtail    0.224827\n",
       "Name: Implied Returns, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implied_returns(2.5,sigma_prior_,w_eq).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = pd.Series([0.03])\n",
    "q = pd.Series([0.05])\n",
    "\n",
    "\n",
    "p = pd.DataFrame([0.]*len(inds),index=inds).T\n",
    "w_rtail = w_eq.loc['Rtail']/(w_eq.loc['Rtail']+w_eq.loc['Whlsl'])\n",
    "w_whlsl = w_eq.loc['Whlsl']/(w_eq.loc['Rtail']+w_eq.loc['Whlsl'])\n",
    "p.iloc[0]['Hlth'] = 1.\n",
    "p.iloc[0]['Rtail'] = -w_rtail\n",
    "p.iloc[0]['Whlsl'] = -w_whlsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.15130613851608934, -0.85)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-w_whlsl,-w_rtail.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hlth     0.19\n",
       "Whlsl    0.19\n",
       "Rtail    0.19\n",
       "Fin      0.17\n",
       "Food     0.14\n",
       "dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta = 2.5\n",
    "tau = 0.05\n",
    "bl_mu, bl_sigma = bl(w_eq, sigma_prior_, p, q, tau = tau)\n",
    "bl_mu.round(2).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Whlsl    0.189645\n",
       "Rtail    0.178307\n",
       "Fin      0.165185\n",
       "Hlth     0.160882\n",
       "Food     0.138245\n",
       "Name: Implied Returns, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implied_returns(2.5,bl_sigma,bl_mu).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse(d):\n",
    "    \"\"\"\n",
    "    Invert the dataframe by inverting the underlying matrix\n",
    "    \"\"\"\n",
    "    return pd.DataFrame(inv(d.values), index=d.columns, columns=d.index)\n",
    "    \n",
    "def w_star(delta, sigma, mu):\n",
    "    return (inverse(sigma).dot(mu))/delta\n",
    "\n",
    "wstar = w_star(delta=2.5, sigma=bl_sigma, mu=bl_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hlth     0.310774\n",
       "Rtail    0.290293\n",
       "Fin      0.167011\n",
       "Food     0.132549\n",
       "Whlsl    0.051754\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wstar.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3715ca10f576a2375282e255376934202de37df0f470497a97d1350df3f9ed2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
